---
title: Traitement automatique des langues
keywords: IA, LLM, TAL
last_updated: June 18, 2024
tags: [IA, LLM, TAL]
summary: "Introdution sur le traitement automatique des langues (TAL)"
sidebar: mydoc_sidebar
permalink: LLM_TAL_intro.html
folder: mydoc
---


3.	Le traitement automatique des langues

Le langage naturel fut l'objet des recherches en IA dès son commencement, regroupées sous la désignation de Traitement Automatique des Langues (TAL) ou Traitement Automatique du Langage Naturel (TALN). Le TAL est ainsi la discipline qui a pour objet le traitement des données textuelles, alors que la linguistique est la science de ces données (Sagot 2023b). De manière générale, le but visé par le TAL est « la compréhension d'une langue par une machine et la communication avec les humains au travers de celle-ci » (Rodriguez 2022, p. 95). Pour ce faire, ses praticiens mêlent outils informatiques et linguistiques dans des travaux qui englobent une large palette de thématiques et aux applications possibles tout autant variées. Celles-ci sont généralement regroupées en quatre tâches principales : l’analyse de texte (ex.: analyse de sentiments, correction orthographique, détection de contenu haineux), la génération de texte (ex. : rédaction d'articles, résumé de vidéos), la transformation de texte (lemmatisation, traduction automatique, résumé automatique, simplification de textes) et les interactions homme-machine (ex. : systèmes de recommandation, systèmes de questions-réponses, agents conversationnels) (Rodriguez 2022, pp. 96-97 ; Sagot 2023a ; Sagot 2024a).Reflétant l’évolution du rapport du TAL à la linguistique, différentes approches méthodologiques ont tour à tour dominé la discipline. 

3.1.	Approches symboliques

Stimulée par le contexte de la guerre froide et la nécessité de traduire les communications de l'ennemi, la recherche sur le traitement par ordinateur des langues se développe concomitamment à l'émergence des fondements de l'IA en tant que champ de recherche (Depaz 2023). En substance, la tâche fondamentale du TAL consistait à « tirer parti d'une analyse linguistique explicite pour extraire de la structure, des informations, de la capacité à généraliser » (Sagot 2023b). Le premier système de traduction automatique a par exemple été présenté au grand public par IBM à New York en 1954 déjà (Zhang et al. 2023). Mémorable, cette expérience présentait plus de cinquante phrases russes traduites en anglais en se basant sur 250 mots et 6 règles syntaxiques (Sagot 2023a). Les années 1960 sont dominées par l’analyse syntaxique, portée notamment par la nouvelle linguistique de Noam Chomsky, qui s'appuie sur des grammaires formelles et des lexiques morphologiques et syntaxiques (Sagot 2023a). Des analyseurs syntaxiques complexes sont mis au point, implémentés dans des algorithmes efficaces de programmation logique (\cite{SagotLA2023}). A peu près à la même période, les premiers agents conversationnels (ELIZA de Weizenbbaum en 1966, PARRY de Colby en 1972) sont développés. Et les systèmes experts appliqués à divers domaines (médecine, planification, gestion des connaissances, etc.), qui « s'appuient sur de grandes quantités de connaissances métier encodées formellement dans la machine » (Sagot 2023a) connaissent leur âge d'or dans les années 1970-80 (Sagot 2023a ; Linden et al. 2023).
Ces premières approches du TAL, dites symboliques ou linguistiques, longtemps majoritaires, s’appuient sur des analyses formelles et descriptives des langues, la construction de grammaires et de lexiques (Sagot 2023b). Elles reposent sur des règles linguistiques définies par les linguistes qui formalisent ainsi le fonctionnement des langues (Vannieuwenh 2019, p. 219). En outre, ces outils précurseurs reposaient sur « les premières techniques de programmation [...] basées sur des modélisations formelles du monde, de ses objets, de ses concepts et des transformations qui peuvent leur être appliquées » (Linden et al. 2023) et visaient la « génération de sens à travers une manipulation de symboles » (Depaz 2023). Ces concepts, stylistiquement marqués par la liste et le symbole, comme le reflète le langage Lisp, imprègnent largement les systèmes IA de l'époque (Depaz 2023).
L'effort humain pour les configurer et définir manuellement les règles demeure toutefois considérable, autant que leur maintenance et leur mise à jour fastidieuses (Kaylan 2023). Sans compter que ces techniques "artisanales", pas favorisées par les capacités matérielles des ordinateurs d'alors, ne sauraient suffire à capter la complexité et les nuances du monde réel. Par leur nature, leur efficacité transparait avant tout dans des situations où les règles peuvent être bien définies, face à des "toy problems" plus qu'en situations réelles, en sorte (Sagot 2023c). Malgré leurs limitations, les approches symboliques demeurent à l’heure actuelle cruciales pour certaines tâches de TAL, par exemple en linguistique formelle, lorsque la description explicite des langues est requise, ou une solution de repli quand le corpus de données est très restreint (Sagot 2023c). De plus, ces systèmes présentent l’avantage de pouvoir être corrigés et améliorés explicitement, et leurs choix sont explicables (Sagot 2023c). Finalement, ils se révèlent moins énergivores que les méthodes neuronales abordées plus loin.

3.2.	Approches statistiques non neuronales

En parallèle aux développements des méthodes issues de l’approche symbolique se dresse l'approche statistique, également qualifiée de stochastique (prévision de la probabilité de l'état futur à l'aune d'une situation donnée ; Depaz 2023). Faisant fi d’une conceptualisation explicite de la connaissance et souffrant d’une moindre explicabilité, celle-ci émerge dans le TAL sous deux formes : soit à des fins de désambiguïsation de systèmes symboliques (par exemple dans les cas où il faut choisir la meilleure réponse parmi plusieurs produites par un système symbolique), soit en tant que modèles intrinsèquement probabilistes ou stochastiques (Sagot 2023c).

Dans les années 80-90, les modèles statistiques non-neuronaux (basés ou non sur le machine learning) ont connu un développement florissant. Capables de manipuler de larges corpus, ils étaient plus précis et performants que les méthodes symboliques et les réseaux de neurone d'alors (Raiaan et al. 2024). Le modèle n-gramme (bigramme si n=2, trigramme si n=3, etc.), où « the count of each n-gram [is] compared against the frequency of each word » (Mohammadi et al. 2019), en constitue un exemple précurseur. Dans une conception markovienne, ce raisonnement probabiliste décompose la probabilité d'une séquence discrète de mots comme un produit des probabilités discrètes d'apparition (les distributions conditionnelles, qui sont ici les paramètres du modèle) des n unités qui le précèdent directement (Yvon 2022) en utilisant la formule de Bayes. Supposant un vocabulaire de taille finie, un tel modèle peut être estimé dans un calcul se basant sur l'occurrence de la séquence dans le corpus (Yvon 2022). Avant l'arrivée de modèles plus sophistiqués, il trouvait déjà des applications diverses telle l'auto-complétion de phrases ou la vérification orthographique. 
Après des premières applications dans le traitement de la parole (à nouveau par IBM), l’apprentissage automatique vient chambouler l’analyse des données textuelles. Ce qui peut être considéré comme la première révolution du TAL (Sagot 2023a), entraine en effet un changement radical dans l’approche scientifique puisqu’on ne programme plus la machine pour effectuer un calcul donné ; à la place, on la laisse apprendre en lui montrant de nombreux exemples. Deux facteurs ont précipité ces développements : d’une part des ordinateurs de puissance de plus en plus conséquente et, d’autre part, de grands corpus de textes annotés au format électronique. L’apprentissage automatique embrasse avec succès tous les champs du TAL dès les années 1990 (2000 pour les textes francophones), avec des réussites probantes notamment dans le domaine des analyseurs syntaxiques statistiques ou de la traduction automatique statistique (Sagot 2023a). Ce revirement n’est pas seulement méthodologique, il implique également une redistribution de l'expertise linguistique. En effet, les représentations du langage et les descripteurs adéquats étant désormais dérivés du corpus lui-même, ce n’est plus tant pour la définition de règles de grammaire ou de lexiques que les connaissances des spécialistes sont mises à profit, mais pour l'annotation des données (Sagot 2023b).
Comme méthode statistique non-neuronale relevant de l'apprentissage automatique supervisé avec des applications possibles en TAL, nous pouvons citer par exemple le classifieur bayésien naïf, qui peut permettre d'identifier les pourriels parmi des messages électroniques (Azencott 2019, p. 62}) ou les machines à vecteur de support. De telles modélisations ont toutefois d'importantes limitations, notamment leur incapacité à tracer des limites de décision non-linéaires et à tenir compte des dépendances longue distance (Leong et al. 2023) ou leur coût en mémoire exponentiel dû au nombre de permutations de mots à calculer (Guimarães et al. 2024). Aussi, elles requièrent un intense travail d'ingénierie de caractéristiques (feature engineering), une étape de pré-traitement dont le deep learning permet de s'affranchir (Kaylan 2023). Ces précurseurs marquent néanmoins une orientation vers des méthodes axées sur les données (data-driven) et posent certaines bases (i.a. vectorisation numérique du texte, apprentissage des paramètres) sur lesquelles s'appuieront les modèles plus complexes réalisant de l'apprentissage profond (Yvon 2022). 

3.3.	Approches neuronales

Inspirées du fonctionnement cérébral, les méthodes neuronales consistent à assembler dans un nombre variable de couches des neurones artificiels reliés entre eux par des connexions (IA connexionniste), dont la force est adaptée lors de l’apprentissage. Ici, le neurone prend la place du symbole comme unité de base, du perceptron de Rosenblatt (1960) aux modèles GPT. Après avoir fructifié dans le domaine de la vision par ordinateur, le déferlement des réseaux de neurones profonds submerge l’analyse du langage et provoque la deuxième révolution du TAL (Sagot 2023a). Celle-ci place les modèles de langue au cœur de la discipline (Sagot 2023a). Nous approfondirons les méthodes neuronales dans les chapitres suivants.
Sous un angle conceptuel, l’approche neuronale, associée à des langages tel que Python, s'assied sur une notation diagrammatique (voir la représentation du modèle Transformer, par exemple ; Depaz 2023). En comparaison à Lisp, on abandonne la « rigueur mathématique pour un gain d’effectivité, laissant les concepts linguistiques se définir de facto et in situ » (Depaz 2023). Ce changement de paradigme stylistique implique également d'adopter une conception spatiale du langage : « il ne s’agit plus de considérer le langage comme une liste atomique d’entités connectées par des liens syntactiques préétablis, mais au contraire comme un espace vectoriel continu à hautes dimensions » (Depaz 2023). Le texte devient une donnée spatiale. 
Par ailleurs, l'approche des modèles neuronaux actuels revêt une dimension systématique : par exemple, là où l'approche symbolique fonctionnait par catégorie de textes (conversations contrôlées, littérature jeunesse, etc.), les modèles profonds abolissent les frontières entre genres de texte, se contentant d'assembler les phrases qui, statistiquement, sont appariées dans les données englouties (Depaz 2023). Alors que le linguiste cherchait à intégrer la connaissance à la machine, la tâche de l'ingénieur en apprentissage automatique consiste à extraire celle implicite aux données en paramétrant et entrainant des modèles (Linden et al. 2023). Aussi, l’extraction des descripteurs (feature engineering) n’est plus requise : là où les modèles consommant peu de données intègrent des biais inductifs déterminés par les experts, les réseaux de neurone d’une certaine envergure apprennent les caractéristiques d’intérêt automatiquement et simultanément au modèle lui-même. Pour cette raison, le « focus shifted to architecture engineering, where inductive bias was rather provided through the design of a suitable network architecture » (Liu et al. 2023a). La frontière entre recherche et ingénierie se déplace (Sagot 2024c).

3.4.	Eléments de TAL

3.4.1.	Les modèles de langue
Un but majeur du TAL réside dans la modélisation du langage. Dans un sens large, un modèle de langue se définit comme « une distribution de probabilité sur toutes les chaines d'une langue » (Charniak 2021, p. 65) ou autrement dit « une distribution de probabilité sur des séquences composées d’unités prises dans un inventaire fini » (Yvon 2022). Formulé plus génériquement, un modèle de langue correspond donc à une modélisation de séquence ordonnée (e.g. une phrase) constituée d'éléments discrets (e.g. un mot) interdépendants (prédiction d'un symbole k à partir des k-1 symboles précédents), dont l'apprentissage ne requiert aucune annotation (Yvon 2022). La modélisation du langage peut également se définir comme la tâche « of predicting what word comes next » ou celle de « assign[ing] a probability to a piece of text» (Hashimoto 2024a). Conceptuellement, un modèle de langue repose sur le principe de compositionnalité sémantique (« nous construisons l'interprétation de chaque phrase en combinant les interprétations individuelles des mots qui la composent » ; Pérez-Ortiz et al. 2022) et l’hypothèse de localité des dépendances « la probabilité d’apparition de l’unité wt est indépendante du passé sachant le contexte constitué des n-1 mots précédents » (Yvon 2022).

Deux principales approches sont mises à profit pour la modélisation du langage (Sagot 2023d). Les approches par comptage s’appuient sur le nombre d’occurrences des séquences de mots dans les données d’entrainement. Dans le modèle n-gramme par exemple, le calcul de la probabilité d’un mot se base sur la fréquence d’apparition de la séquence de mots (n-gramme) apparaissant avant lui comptabilisée dans le corpus. La capacité de ce type de modèles à prendre en compte les relations entre les mots est donc très restreinte : un modèle 3-gramme ne considérera que les 2 mots qui précédent immédiatement celui à prédire (Sagot 2023d). Par leur fonctionnement, ils sont également limités pour le traitement des séquences rares (sparsity problem) et rencontrent des défis de stockage (storage problem) puisque les occurrences de tous les n-grammes doivent être gardés en mémoire (Mohammadi et al. 2019). Les approches par prédiction, quant à elles, se basent sur le contexte pour prédire le mot le plus probable en fournissant un score interprétable comme une probabilité (Sagot 2023d). Avec l’avènement des méthodes neuronales profondes, ce type de modèles de langue a été placé au cœur du TAL (Sagot 2023a). Si seul le contexte de gauche est considéré (dans le but de prédire le mot suivant), les modèles sont dits génératifs (ou causaux) (modèles GPT par exemple). Ceux-ci se basent soit sur une prédiction autorégressive – quand celle-ci s’effectue de façon séquentielle : le modèle doit être exécuté séparément pour chacun des tokens , ce qui ralentit l’entrainement et l’inférence ; soit sur une prédiction non-autorégressive – quand la distribution de probabilités est estimée simultanément pour tous les tokens, l’exécution des modèles est alors plus rapide, mais leur performance moindre (Sagot 2023d). Si le contexte complet est considéré (dans le but de prédire le mot manquant), les modèles sont dits par masquage (ou non-causaux) (modèle BERT par exemple). En outre, un modèle de langue peut être qualifié de conditionnel quand la probabilité assignée dépend d’une autre séquence, par exemple d’un prompt. La plupart des modèles de langue conditionnels sont génératifs (Sagot 2023d). Des modèles de langue prédictifs conditionnels particuliers sont ceux opérant séquence-à-séquence (seq2seq) : la prédiction tient compte d’une séquence conditionnante (par exemple en combinant un encodeur – qui permet de capter le contexte global – suivi d’un décodeur, qui lui fonctionne de manière causale) (Sagot 2023d).
Les modèles de langue neuronaux peuvent avoir plusieurs finalités. Logiquement, ils peuvent être utilisés pour leurs tâches initiales (par exemple la génération de texte) – c’est souvent le cas des modèles génératifs. Mais ils peuvent également servir à initialiser ou à affiner un réseau de neurones dans un but particulier (pré-entrainement). Pour la traduction automatique par exemple, on a fréquemment recours à des modèles encodeur-décodeur affinés. Et finalement, comme nous allons le voir dans la section suivante, ils peuvent fournir des embeddings de qualité à un autre réseau de neurone consacré à une tâche spécifique. C’est à cette fin que sont souvent utilisés les modèles par masquage (Sagot 2023d).

3.4.2.	Représentations vectorielles des mots
Pour pouvoir être manipulables efficacement par des modèles mathématiques, les mots doivent être convertis en format numérique et représentés dans « un espace vectoriel qui en capture beaucoup mieux la signification profonde » (plongement lexical ou word embedding ; Bersini et Hasselmann 2023, p. 131). L’objectif étant par ailleurs que ce format numérique capture la sémantique, les relations syntaxiques et le contexte des mots afin d’optimiser leur traitement et leur analyse ultérieurs. Par ailleurs, en rapprochant les représentations de mots similaires, cette forme permet de faciliter les généralisations, conformément à l'hypothèse distributionnelle (« deux mots sont similaires s'ils apparaissent dans les mêmes contextes » ; Sagot 2023c, selon Harris 1954). Le contexte fait ici référence à l'ensemble des mots qui figurent à proximité (dans une fenêtre de taille fixe) et les différents contextes d’un mot dans un corpus sont utilisés pour construire une représentation de ce mot (Yang et Hashimoto 2024).
Les premières méthodes de représentation des mots se basaient sur l’encodage one-hot : après avoir défini un vocabulaire de taille fixe dont la dimension détermine la taille des longueurs de mots, le i-ème mot du vocabulaire est représenté en remplissant le vecteur de zéros à l’exception de la position i qui contient un 1. De toute évidence, cette méthode n’est pas la plus adéquate : les mots n’ont rien en commun entre eux (produit scalaire nul) – « haricot »/« trottoir » sont autant similaires que « pomme »/« poire ». Ainsi, avec un tel encodage, il n’est pas possible d’apprendre des généralisations (Sagot 2023b).
Des méthodes ont donc été développées pour obtenir des représentations vectorielles des mots qui soient plus informatives. Les embeddings non-contextuels travaillent sur un grand corpus de données pour fournir une représentation vectorielle unique pour chaque mot. Pour les obtenir, les approches statistiques (par comptage) proposent notamment des méthodes basées sur des matrices de co-occurrence (mot-mot ou mot-document) soumises ensuite éventuellement à des méthodes de réduction de dimensionnalité par exemple pour obtenir des vecteurs denses aux propriétés satisfaisantes (Sagot 2023b). Elles ne capturent par contre qu’une information limitée concernant le contexte des mots et les mots rares sont difficiles à représenter correctement. Utilisant une information statistique globale, ces méthodes dites count-based captent la similarité des mots mais performent mal pour des tâches comme l’analogie entre les mots, « indicating a sub-optimal vectore space structure » (Mundra et al. 2019). Certaines méthodes, comme GloVe (Pennington et al. 2014), un « weighted least squares model that trains on global word-word co-occurrence counts » (Mundra et al. 2019), innovent en combinant analyse des statistiques globales de co-occurrence, avec de l’apprentissage. Les approches prédictives, principalement neuronales, apportent des améliorations en apprenant les embeddings directement des données textuelles. Dans ce cas, les vecteurs de la couche cachée (ou couche de projection) servent de plongements lexicaux. Les valeurs du vecteur du plongement sont initialisées aléatoirement puis mises à jour au cours de l'apprentissage. Des mots au sens similaire sont représentés par des vecteurs qui pointent dans la même direction et cette proximité peut être capturée par des métriques telles que la similarité cosinus (Charniak 2021, p. 68). Ces méthodes, dont la plus connue est Word2vec (Mikolov et al. 2013 ; voir section 4.2.), ont connu un succès certain car elles permettent de structurer l’espace sémantique. La représentation vectorielle du mot qui en résulte permet également d'effectuer des opérations arithmétiques reflétant des analogies de mots du type : Roi - Homme + Femme = Reine ou Rome - Italie + France = Paris. Bien qu’ils utilisent le contexte des mots lors de l’apprentissage, les embeddings ainsi obtenus présentent l’inconvénient d’être non-contextuels (le fruit « avocat » a la même représentation vectorielle que l’« avocat » de métier). Les modèles de langue neuronaux les plus modernes pallient cette limitation en fournissant des embeddings contextuels (voir chapitre suivant), assurant ainsi d’obtenir des vecteurs proches pour des paires (mot, contexte) similaires (Sagot 2023a ; Sagot 2023c ; Sagot 2023d). 
Ainsi donc, si les recherches sur ces deux composantes majeures du TAL que ce sont les modèles de langue et les word embeddings ont d’abord évolué en parallèle, elles ont fini par se rejoindre puisque les modèles de langue modernes créent simultanément des représentations vectorielles contextuelles des mots (Sagot 2023b). 



{% include links.html %}
