---
title: Divers
keywords: IA, IT
last_updated: June 30, 2024
tags: [IA]
summary: "autres infos et sujets divers"
sidebar: mydoc_sidebar
permalink: IA_divers.html
folder: mydoc
---


## A suivre

(non exhaustif)

* IA dans le [canton de Zurich](https://www.zh.ch/de/politik-staat/kanton/kantonale-verwaltung/digitale-verwaltung/kuenstliche-intelligenz.html), dont repo [GitHub](https://github.com/machinelearningZH)
* [ParlDebateScanner](https://parldebatescanner.org/) in a Nutshell [source code](https://github.com/JohannesHool/parldebatescanner-in-a-nutshell)
* [Swiss OSS benchmarks](https://ossbenchmark.com/) : Ranking of Swiss Institutions/Repo/People Releasing Open Source Software
* [Atlas of automation](https://algorithmwatch.ch/en/atlas-of-automation/) par AlgorithmWatch
* DemoSquare github account with [swissparly](https://github.com/DemoSquare/swissparlpy) python package for connecting [swiss parlament API](https://ws.parlament.ch/odata.svc)
* Mistral jupyter cookbooks ([github](https://github.com/mistralai/cookbook/blob/main)) 

## RAG and agents

* [Building an Agent for Data Visualization (Plotly)](https://medium.com/firebird-technologies/building-an-agent-for-data-visualization-plotly-39310034c4e9) (with code source examples)
* [Implementing Agentic RAG using Langchain](https://medium.com/the-ai-forum/implementing-agentic-rag-using-langchain-b22af7f6a3b5) (with code source examples)


## Ressources en ligne

(non exhaustif)

https://github.com/microsoft/generative-ai-for-beginners/tree/main

https://huggingface.co/learn

https://github.com/mistralai/cookbook/tree/main

https://acoustic-licorice-c24.notion.site/Guide-Complet-Utiliser-GPT-4o-en-milieu-professionnel-0657016ce3b34ae6add98af012b11850

## Vidéos

* Institut Public Sector Transformation (IPST) [You Tube](https://www.youtube.com/@IPST_BFH) Vidéos (e.g. TRANSFORM conférences)
* [DataScientest](https://www.youtube.com/watch?v=RqZdJyP85NQ&ab_channel=DataScientest) Youtube webinars (e.g. IA dans PowerBI)
* [ENI](https://www.youtube.com/@EditionsENI/videos) Youtube webinars (e.g. Copilot Pro)

## Audio

<https://www.rts.ch/audio-podcast/2023/audio/l-invite-de-la-matinale-eric-sadin-ecrivain-et-philosophe-27184936.html>

[Club 44, 15.11.23 - L'intelligence artificielle n'existe pas - Luc Julia](https://vimeo.com/892181556)

<!---

<https://www.radiofrance.fr/franceinter/podcasts/la-tete-au-carre/l-intelligence-artificielle-2354320>
<https://www.radiofrance.fr/franceinter/podcasts/grand-bien-vous-fasse/comment-l-intelligence-artificielle-va-continuer-a-revolutionner-notre-vie-quotidienne-3546453>
<https://www.radiofrance.fr/radiofrance/podcasts/serie-l-intelligence-artificielle-en-questions>
<https://www.radiofrance.fr/franceculture/podcasts/serie-l-ia-l-intelligence-artificielle>
<https://www.radiofrance.fr/franceculture/podcasts/serie-ce-que-l-intelligence-artificielle-fait-a-l-emploi>
<https://www.radiofrance.fr/franceculture/podcasts/journal-de-12h30/journal-de-12h30-du-vendredi-15-septembre-2023-4472149>
<https://www.radiofrance.fr/franceinter/podcasts/carnets-de-campagne/carnets-de-campagne-du-lundi-11-septembre-2023-4787494>
<https://www.radiofrance.fr/franceinter/podcasts/cyberpouvoirs/cyberpouvoirs-du-dimanche-23-juillet-2023-6125795>
<https://www.radiofrance.fr/francebleu/podcasts/a-votre-service-par-france-bleu-poitou/pourquoi-l-intelligence-artificielle-fait-elle-peur-2295349>
<https://www.radiofrance.fr/franceinter/podcasts/le-telephone-sonne/le-telephone-sonne-du-mercredi-12-avril-2023-2261962>
<https://www.radiofrance.fr/franceinfo/podcasts/le-talk-franceinfo/l-intelligence-artificielle-va-t-elle-detruire-nos-emplois-2566500>
<https://www.radiofrance.fr/franceinter/podcasts/interception/interception-du-dimanche-12-mars-2023-8991139>
<https://www.radiofrance.fr/francebleu/podcasts/c-est-la-vie/intelligence-artificielle-chat-gpt-vous-veut-il-du-bien-1109841>
<https://www.radiofrance.fr/franceinter/podcasts/la-terre-au-carre/la-terre-au-carre-du-mercredi-12-avril-2023-7653937>
<https://www.radiofrance.fr/franceinter/intelligence-artificielle-sommes-nous-prets-6699930>
<https://www.radiofrance.fr/franceculture/podcasts/le-pourquoi-du-comment-economie-et-social/pourquoi-l-intelligence-artificielle-ne-va-t-elle-pas-necessairement-detruire-nos-emplois-8745349>
<https://www.radiofrance.fr/francebleu/podcasts/l-invite-d-actu-de-8h15-france-bleu-paris/intelligence-artificielle-il-ne-faut-pas-en-avoir-peur-il-faut-avoir-peur-de-ce-que-les-humains-en-font-6119643>
<https://www.radiofrance.fr/francebleu/podcasts/ma-france/ma-france-l-intelligence-artificielle-commence-a-entrer-dans-nos-vies-5682919>
<https://www.radiofrance.fr/franceculture/podcasts/avec-philosophie/l-intelligence-artificielle-est-elle-vraiment-intelligente-2059509>
<https://www.radiofrance.fr/franceculture/podcasts/l-esprit-public/intelligence-artificielle-cauchemar-ou-revolution-3452284>
<https://www.radiofrance.fr/franceinter/podcasts/l-invite-de-8h20-le-grand-entretien/l-invite-de-8h20-le-grand-entretien-du-jeudi-02-mars-2023-6866012>
<https://www.radiofrance.fr/franceculture/podcasts/matieres-a-penser-avec-rene-frydman/les-secrets-de-l-intelligence-artificielle-7051712>
<https://www.radiofrance.fr/franceinter/podcasts/la-tete-au-carre/les-enjeux-ethiques-de-l-intelligence-artificielle-5814298>
<https://www.radiofrance.fr/francebleu/podcasts/cote-experts/faut-il-avoir-peur-de-l-intelligence-artificielle-7316470>
<https://www.radiofrance.fr/franceculture/podcasts/signes-des-temps/incidence-et-risque-des-nouveaux-usages-de-l-intelligence-artificielle-dans-le-domaine-politique-et-culturel-1366763>
<https://www.radiofrance.fr/franceculture/podcasts/l-invite-e-des-matins/les-progres-de-l-intelligence-artificielle-vont-ils-rendre-le-travail-obsolete-5887764>
<https://www.radiofrance.fr/franceinfo/podcasts/le-talk-franceinfo/chatgpt-l-intelligence-artificielle-va-t-elle-remplacer-les-humains-4210643>
<https://www.radiofrance.fr/franceculture/podcasts/la-grande-table-2eme-partie/cedric-villani-l-intelligence-en-marche-3294764>

-->

## Références


Ada Lovelace Institute. 2023. Foundation models in the public sector. Evidence review, 110 pages.
Alammar Jay. 2018. The Illustrated Transformer. Consulté le 24.02.2024. https://jalammar.github.io/illustrated-transformer.
Ali Omar, Murray Peter A., Momin Mujtaba, et al.. 2024. The effects of artificial intelligence applications in educational settings: Challenges and strategies. Technological Forecasting and Social Change 199, pp. 1-18.
Ammann Jeanine, Walter Achim et El Benni Nadja. 2022. Wahrnehmung und Adoption von Farmmanagementinformationssystemen unter künftigen Betriebsleitenden. Dans: Informatik in der Land-, Forst- und Ernährungswirtschaft: Fokus: Künstliche Intelligenz in der Agrar- und Ernährungswirtschaft; Referate der 42. GIL-Jahrestagung. 21.–22. Februar, Ed. Gesellschaft für Informatik e.V. (GI), Bonn. 2022, pp. 33-38.
Amnesty International. 2021. Pays-Bas. Scandale des allocations familiales : un avertissement qui montre l’urgence d’interdire les algorithmes racistes. Consulté le 15.02.2024. https://www.amnesty.org/fr/latest/news/2021/10/xenophobic-machines-dutch-child-benefit-scandal.
Arkhangelskaya E. O. et Nikolenko S. I.. 2023. Deep Learning for Natural Language Processing: A Survey. Journal of Mathematical Sciences 273(4), pp. 533-582. 
Azencott Chloé-Agathe. 2019. Introduction au Machine Learning. Dunod, 272 pages.
Badri Sami, Abrams Sami, Liu Haas, et al.. 2023. ChatGPT: Unlocking the Potential of Large Language Models. Credit Suisse Connection Series, 105 pages.
Bahdanau Dzmitry, Cho Kyung Hyun et Bengio, Yoshua. 2015. Neural machine translation by jointly learning to align and translate. 3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings, pp. 1-15.
Barbey Grégoire. 2024. Au Tribunal fédéral, l’informatique se passe des géants américains. Le Temps. https://www.letemps.ch/cyber/au-tribunal-federal-l-informatique-se-passe-des-geants-americains.
Bastien L. 2024. ChatGPT jailbreak : toutes les techniques pour désactiver la censure. Consulté le 29.01.2024. https://www.lebigdata.fr/chatgpt-dan.
Baudet Cédric, Medina Maximiliano Jeanneret, Delaloye Matthieu et al.. 2023. Des IA et des hommes. Association Information et Management – Dijon 2023, pp. 1-33.
Bender Emily M., Gebru Timnit, McMillan-Major Angelina et al.. 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big ? FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.
Bengio Yoshua, Ducharme Réjean, Vincent Pascal et al.. 2003. A Neural Probabilistic Language Model. Journal of Machine Learning Research 3, pp. 1137-1155. 
Bersini Hugues et Hasselmann Ken. 2023. L'intelligence artificielle en pratique avec Python: Recherche, optimisation, apprentissage. Editions Eyrolles, 176 pages.
Blangeois Morgan. 2023. IA Générative : Révolution Ou Menace Pour Les Entreprises Des Services Du Numérique ? Management & Data Science 7(4).
Bommasani Rishi, Hudson Drew A., Adeli Ehsan et al.. 2021. On the Opportunities and Risks of Foundation Models. arXiv, pp. 1-214.
Boulanger Hugo. 2023. Data Augmentation and Generation for Natural Language Processing. Thèse de doctorat de l’université Paris-Saclay, 133 pages.
Byk Christian et Piana Daniela. 2021. L’intelligence artificielle : un « concept flottant » entre apparence de consensus normatif et controverse cachée sur le projet de société. Droit, Santé et Société N° 3, pp. 76-98. 
Brown Tom B., Mann Benjamin, Ryder,Nick et al.. 2020. Language models are few-shot learners. Advances in Neural Information Processing Systems 33 (NeurIPS 2020), pp. 1-25.
Campion Averill, Hernandez Mila-Gasco, Mikhaylov Jankin Slava et al.. 2020. Managing Artificial Intelligence Deployment in the Public Sector. Computer 53(10), pp. 28-37.
Cantens Thomas. 2023. Comment pensera l’État avec ChatGPT ? Les douanes comme illustration de l’intelligence artificielle générative dans les administrations publiques. Ferdi Document de travail P330, 28 pages.
Cao Yihan, Li Siyu, Liu Yixin et al.. A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT. Journal of the ACM 37(4), pp. 1-44.
Charniak Eugene. 2021. Introduction au Deep Learning. Dunod, 176 pages.
Chaubard Francois et Socher Richard. 2019. Lecture Notes: Part VIII Convolutional Neural Networks – CS 224n: Natural Language Processing with Deep Learning. Stanford University. https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes08-CNN.pdf.
Cheng Jianpeng, Dong Li et Lapata Mirella. 2016. Long short-term memory-networks for machine reading. EMNLP 2016 - Conference on Empirical Methods in Natural Language Processing, Proceedings, pp. 551-561. 
Corric Johann. 2023. ChatGPT entre déjà dans les habitudes des salaries. L’AGEFI. https://www.agefi.fr/news/economie-marches/chatgpt-entre-deja-dans-les-habitudes-des-salaries.
Council of the European Union (CEU). 2023. ChatGPT in the Public Sector - overhyped or overlooked ? Art-Research paper, 23 pages.
Corthésy Matthieu. 2023. ChatGPT en entreprise - Le guide complet pour maximiser votre productivité. Diateino Eds, 271 pages.
Côté Anne-Marie et Su Zhan. 2021. Évolutions de l’intelligence artificielle au travail et collaborations humain-machine. Ad machina 5, pp. 144-160.
Courrier International. 2023. IA – Le bot du Pôle emploi autrichien refuse d’orienter les femmes vers l’informatique. Consulté le 30.01.2024. https://www.courrierinternational.com/article/ia-le-bot-du-pole-emploi-autrichien-refuse-d-orienter-les-femmes-vers-l-informatique.
Courtier-Orgogozo Virginie et Devillers Laurence. 2024. La société face aux avancées des sciences et des techniques - Le cas de l’intelligence artificielle et de la génétique. Futuribles 458, pp. 1-20. 
Dale Robert. 2021. GPT-3: What's it good for ? Natural Language Engineering 27(1), pp. 113-118.
Dasgupta Dipankar, Venugopal Deepak et Gupta Kishor Datta. 2023. A Review of Generative AI from Historical Perspectives. TechRxiv, pp. 1-9.
Delbecq Denis. 2024. Comment les mathématiques révolutionnent l’IA pour les appareils mobiles et les supercalculateurs. Consulté le 15.03.2024. Le Temps. https://www.letemps.ch/sciences/l-ia-en-quete-de-sobriete-ou-de-performance.
Depaz Pierre. 2023. Stylistique de la recherche linguistique en IA: de LISP à GPT-3. Créativités artificielles – La littérature et l’art à l’heure de l’intelligence artificielle, pp. 1-15.
Devlin Jacob, Chang Ming Wei, Lee Kenton et al.. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186.
Dey Roshmita. 2023. Understanding Language Modeling: From N-grams to Transformer-based Neural Models. Consulté le 01.02.2024. https://medium.com/@roshmitadey/understanding-language-modeling-from-n-grams-to-transformer-based-neural-models-d2bdf1532c6d
Doshi Ketan. 2021. Foundations of NLP Explained Visually: Beam Search, How It Works. Consulté le 24.02.2024. https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24.
EPFL. 2023. Ensemble pour une intelligence artificielle digne de confiance. Consulté le 03.01.2024. https://actu.epfl.ch/news/ensemble-pour-une-intelligence-artificielle-digne-/.
Ezratty Olivier. 2019. Les fumeuses prévisions sur le futur de l'emploi. Constructif 54(3), pp. 11-15. 
Forney Jérémie et Epiney Ludivine. 2022. Gouverner les agriculteurs par les données ? Digitalisation et autonomie dans la gouvernance agro-environnementale. Working Paper series MAPS 2, 22 pages. https://www.unine.ch/files/live/sites/maps/files/shared/documents/wp/WP_2_2022_Forney_Epiney.pdf
Frécon Louis et Kazar Okba. 2009. Manuel d’intelligence artificielle. METIS Lyon Tech, 778 pages.
Gallego Vìctor et Rìos Insua David. 2022. Current Advances in Neural Networks. Annual Review of Statistics and Its Application 9, pp. 197-222.
Genthial Guillaume, Liu Lucas, Oshri Barak et al.. 2019. Lecture Notes: Part VI Neural Machine Translation, Seq2seq and Attention – CS 224n: Natural Language Processing with Deep Learning. Stanford University. https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf.
Groher Tanja, Heitkämper Katja et Umstätter Christina. 2020. Nutzung digitaler Technologien in der Schweizer Landwirtschaft. Agrarforschung Schweiz 11, pp. 59-67. 
Guimarães Nuno, Campos Ricardo et Jorge Alìpio. 2024. Pre-trained language models: What do they know ? Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 14, pp. 1-10. 
Hadi Muhammad Usman, Al-Tashi Qasem, Qureshi Rizwan et al.. 2023. Large Language Models: A Comprehensive Survey of its Applications Challenges, Limitations, and Future Prospects. TechRxiv, pp. 1-43.
Hashimoto Tatsunori. 2024a. Lecture 5: Language Models and Recurrent Neural Networks (slides) – Natural Language Processing with Deep Learning CS224N. Stanford University. https://web.stanford.edu/class/cs224n/slides/cs224n-2024-lecture05-rnnlm.pdf.
Hashimoto Tatsunori. 2024b. Lecture 6: LSTM RNNs and Neural Machine Translation (slides) – Natural Language Processing with Deep Learning CS224N. Stanford University. https://web.stanford.edu/class/cs224n/slides/cs224n-2024-lecture06-fancy-rnn.pdf.
Hashimoto Tatsunori. 2024c. Lecture 8: Self-Attention and Transformers (slides) – Natural Language Processing with Deep Learning CS224N. Stanford University. https://web.stanford.edu/class/cs224n/slides/cs224n-2024-lecture08-transformers.pdf.
Hashimoto Tatsunori. 2024d. Lecture 9: Pretraining (slides) – Natural Language Processing with Deep Learning CS224N. Stanford University. https://web.stanford.edu/class/cs224n/slides/cs224n-2024-lecture09-pretraining.pdf.
Hashimoto Tatsunori. 2024e. Lecture 11: Instruction Finetuning, and RLHF (slides) – Natural Language Processing with Deep Learning CS224N. Stanford University. https://web.stanford.edu/class/cs224n/slides/cs224n-2024-lecture11-instruction-tuning-rlhf.pdf.
Hashimoto Tatsunori. 2024f. Open problems and discussion (slides) – Natural Language Processing with Deep Learning CS224N. Stanford University. https://web.stanford.edu/class/cs224n/slides/cs224n-2024-lecture19-open-problems.pdf
Hewitt John. 2023. Note 10: Self-Attention & Transformer – CS 224n: Natural Language Processing with Deep Learning [draft]. Stanford University. https://web.stanford.edu/class/cs224n/readings/cs224n-self-attention-transformers-2023_draft.pdf.
Hochreiter Sepp et Schmidhuber Jürgen. 1997. Long short-term memory. Neural computation 9(8), pp. 1735-1780.
Hoffmann Jordan, Borgeaud Sebastian, Mensch Arthur, et al.. 2022. Training Compute-Optimal Large Language Models. aRxiv, pp. 1-36.
Hugging Face. 2022. NLP Course – The Hugging Face Course. Consulté le 05.01.2024. https://huggingface.co/learn/nlp-course.
Huot Charles. 2022. Tendances et perspectives de l’intelligence artificielle dans le secteur de l’information-documentation : vision prospective R&D et applications dans le monde des affaires. I2D - Information, données & documents 1, pp. 88-96.
Julia Luc. 2023. L’intelligence artificielle n’existe pas. Conférence au Club 44 (La Chaux-de-Fonds), 15 novembre 2023.
Khanna Chetna. 2021. WordPiece: Subword-based tokenization algorithm. Consulté le 30.12.2024. https://towardsdatascience.com/wordpiece-subword-based-tokenization-algorithm-1fbd14394ed7.
Kocoń Jan, Cichecki Igor, Kaszyca Oliwier et al.. 2023. ChatGPT: Jack of all trades, master of none. Information Fusion 99, pp.1-37.
La Déclaration de Montréal pour un développement responsable de l’intelligence artificielle, 2018. https://declarationmontreal-iaresponsable.com/la-declaration. 21 pages.
LeCun Yann. 2024. Séminaire du 9 février 2024 : L'IA axée sur les objectifs : vers des machines capables d'apprendre, de raisonner et de planifier (enseignement “Apprendre les langues aux machines”). Collège de France (vidéo 16).
Leong Kelvin, Sung Anna et Jones Lewis. 2023. The core technology behind and beyond ChatGPT: A comprehensive review of language models in educational research International Journal of Educational Research and Innovation 20, pp. 1-21.
Kalyan Katikapalli Subramanyam. 2023. A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4. Natural Language Processing Journal, pp. 1-58.
Koubaa Anis, Boulila Wadii, Ghouti Lahouari et al.. 2023. Exploring ChatGPT Capabilities and Limitations: A Survey. IEEE Access 11, pp. 118698-118721.
Lewis Mike, Liu Yinhan, Goyal Naman et al.. 2020. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 7871-7880.
Linden Isabelle, Tilman Valérie et Laurent Nathanaël. 2023. Les techniques d’intelligence artificielle : histoire, développements et défis. Recherches de Science Religieuse 4(111), pp. 603-624.
Liu Pengfei, Yuan Weizhe, Fu Jinlan et al.. 2023a. Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. ACM Computing Surveys 55 (9), pp. 1-35.
Liu Yi, Deng Gelei, Xu Zhengzi et al.. 2023b. Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study. arXiv, pp. 1-12.
Longoni Chiara, Cian Luca et Kyung Ellie J.. 2023. Algorithmic Transference: People Overgeneralize Failures of AI in the Government. Journal of Marketing Research 60(1), pp. 170-188.
Mack Gabriele, Stoinescu Andrei und Heitkämper Katja. 2019. Zur Wahrnehmung des administrativen Aufwandes. Agroscope Science 92, 47 pages.
Madan Rohit et Ashok Mona. AI adoption and diffusion in public administration: A systematic literature review and future research agenda. Government Information Quarterly 40(1), pp. 1-18.
Madonna Lena. 2023. Comment les employés trichent en utilisant l'IA. PME Magazine. https://www.pme.ch/strategie/2023/12/27/comment-les-employes-trichent-en-utilisant-lia-667317.
Maragno Giulia, Tangi Luca, Gastaldi Luca et al.. 2023. Exploring the factors, affordances and constraints outlining the implementation of Artificial Intelligence in public sector organizations. International Journal of Information Management 73, pp. 1-15.
Ménissier Thierry. 2022. Jusqu’où l’institution peut-elle être augmentée ? Pour une éthique publique de l’IA. Quaderni 1/105, pp. 73-88.
Mercier Etienne, Latrille Pierre, Leray Alexandre. 2023. Premier anniversaire de Chat GPT, 77% des Français voient cet outil comme une révolution. Consulté le 13.01.2024. https://www.ipsos.com/fr-fr/premier-anniversaire-de-chat-gpt-77-des-francais-voient-cet-outil-comme-une-revolution.
Mergel Ines, Dickinson Helen, Jari Stenvall et al.. 2023. Implementing AI in the public sector. Public Management Review, pp. 1-13.
Mettler Tobias. 2019. The Road to Digital and Smart Government in Switzerland. In: Swiss Public Administration. Governance and Public Management (de Ladner Andreas, Soguel, Nils, Emery Yves, et al.). Palgrave Macmillan, 384 pages.
Mettler Tobias. 2023. Transformation digitale. Dans : Comprendre et concevoir l’administration publique – Le modèle IDHEAP (de Soguel Nils, Bundi Pirmin, Mettler Tobias et al.). Presses polytechniques et universitaires romandes, 343 pages.
Mikolov Tomas, Chen Kai, Corrado Greg, et al.. 2013. Efficient Estimation of Word Representations in Vector Space. arXiv, pp. 1-12.
Mohammadi Milad, Mundra Rohit, Socher Richard et al.. 2019. Lecture Notes Part V - Language Models, RNN, GRU and LSTM - CS224n: Natural Language Processing with Deep Learning. Stanford University. https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes05-LM_RNN.pdf.
Mougeot Nicolas. 2023. L’IA et le paradoxe de Solow. Bilan. Consulté le 27.01.24. https://www.bilan.ch/story/lia-et-le-paradoxe-de-solow-367553604398.
Mundra Rohit, Peng Emam, Socher Richard, et al.. 2019. Lecture Notes Word Vectors II: GloVe, Evaluation and Training - CS224n: Natural Language Processing with Deep Learning. Stanford University. https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes02-wordvecs2.pdf
Nazir Anam et Wang Ze. 2023. A comprehensive survey of ChatGPT: Advancements, applications, prospects, and challenges. Meta-Radiology 1(2), pp. 1-12.
Neumann Oliver. 2023. Stratégie. Dans : Comprendre et concevoir l’administration publique – Le modèle IDHEAP (de Soguel Nils, Bundi Pirmin, Mettler Tobias et al.). Presses polytechniques et universitaires romandes, 343 pages.
Neumann Oliver et Mettler Tobias. 2023. Innovation. Dans : Comprendre et concevoir l’administration publique – Le modèle IDHEAP (de Soguel Nils, Bundi Pirmin, Mettler Tobias et al.). Presses polytechniques et universitaires romandes, 343 pages.
OpenAI. 2023. GPT-4 System Card. 60 pages.
Ouyang Long, Wu Jeff, Jiang Xu et al.. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35, pp. 1-15.
Pechtor Vàclav et Basl Josef. 2023. Unraveling the Processes and Challenges of Artificial Intelligence Implementation in the Swiss Public Sector: a Toe Framework Analysis. IDIMT 2023: New Challenges for ICT and Management - 31st Interdisciplinary Information Management Talks, pp. 203-215.
Pennington Jeffrey, Socher Richard et Manning Christopher. 2014. GloVe: Global Vectors for Word Representation. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1532-1543.
Pérez-Ortiz Juan Antonio, Palmieri Sébastien, Forcada Mikel L. et al.. 2022. Le fonctionnement de la traduction automatique neuronale. À tradire. Didactique de la traduction pragmatique et de la communication technique 1.
Peters Matthew E., Neumann Mark, Zettlemoyer Luke et al.. 2018. Dissecting contextual word embeddings: Architecture and representation. arXiv, pp. 1-17. 
Poupart Pascal. 2019. CS480/680 Lecture 19: Attention and Transformer Networks. https://www.youtube.com/watch?v=OyFJWRnt_AY&ab_channel=PascalPoupart. 
Press Ofir, Smith Noah et Lewis Mike. 2022.Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation. ICLR 2022 Conference paper, pp. 1-25.
Radford Alec, Narasimhan Karthik, Salimans Tim et al.. 2018. Improving language understanding by generative pre-training. Preprint, pp. 1-12.
Radford Alec, Wu Jeffrey, Child Rewon et al.. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8), 9.
Raffel Colin, Shazeer Noam M., Roberts Adam et al.. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research 21, pp. 1-67.
Ragetly Mathieu. 2023. L’IA Générative au service des résultats. Consulté le 13.02.2024. Bilan. https://www.bilan.ch/story/perspectives-lia-generative-au-service-des-resultats-695873785996.
Raiaan Mohaimenul Azam Khan, Mukta Md. Saddam Hossain, Fatema Kaniz et al.. 2024. A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges. IEEE Access, pp. 1-36.
Reissig Linda. 2023. The understanding of digitalisation in agriculture by small-scale farmers: The importance of clear terminology. Preprint research paper, 25 pages. https://www.agroscope.admin.ch/agroscope/de/home/themen/wirtschaft-technik/betriebswirtschaft/publikationen/_jcr_content/par/externalcontent.bitexternalcontent.exturl.pdf/aHR0cHM6Ly9pcmEuYWdyb3Njb3BlLmNoL2ZyLUNIL1BhZ2UvRW/luemVscHVibGlrYXRpb24vRG93bmxvYWQ_ZWluemVscHVibGlr/YXRpb25JZD01Nzk2OQ==.pdf.
Reissig Linda, Stoinescu Andrei et Mack Gabriele. 2022. Why farmers perceive the use of e-government services as an administrative burden: A conceptual framework on influencing factors. Volume 89, January 2022, pp.387-396.
Rodriguez Jean-Michel. 2022. Intelligence Artificielle - Impact sur les entreprises et le business. ENI, 468 pages.
Vannieuwenh Aurélien. 2019. Intelligence artificielle vulgarisée - Le Machine Learning et le Deep Learning par la pratique. ENI, 480 pages.
Sagot Benoît. 2023a. Leçon inaugurale du 30 novembre 2023. Collège de France.
Sagot Benoît. 2023b. Cours du 08 décembre 2023 : Représenter les unités textuelles (enseignement “Apprendre les langues aux machines”). Collège de France (vidéo 1). 
Sagot Benoît. 2023c. Cours du 15 décembre 2023 : Approches symboliques et probabilistes (enseignement “Apprendre les langues aux machines”). Collège de France (vidéo 3).
Sagot Benoît. 2023d. Cours du 22 décembre 2023 : Modèles de langue (enseignement “Apprendre les langues aux machines”). Collège de France (vidéo 5). 
Sagot Benoît. 2024a. Cours du 19 janvier 2024 : Approches neuronales pour quelques tâches applicatives (enseignement “Apprendre les langues aux machines”). Collège de France (vidéo 9).
Sagot Benoît. 2024b. Cours du 02 février 2024 : Converser avec la machine (enseignement “Apprendre les langues aux machines”). Collège de France (vidéo 13).
Sagot Benoît. 2024c. Cours du 9 février 2024 : Multimodalités : TAL et images, TAL et parole (enseignement “Apprendre les langues aux machines”). Collège de France (vidéo 15).
Seydtaghia Anouch. 2023. L’EPFL lance un centre dédié à l’intelligence artificielle, avec des ambitions internationales. Le Temps. Consulté le 28.02.2024. https://www.letemps.ch/economie/l-epfl-lance-un-centre-dedie-a-l-intelligence-artificielle-avec-des-ambitions-internationales.
Shoeybi Mohammad, Patwary Mostofa, Puri Raul et al.. 2019. Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism. arXiv, pp. 1-15.
Simseo. 2023. Modèle de fondation moins transparent dans le classement de Stanford. Consulté le 11.02.2024. https://simseo.fr/modele-de-fondation-moins-transparent-dans-le-classement-de-stanford.
Stocker Christian. 2023. Demande à LausanneGPT tout sur l'administration lausannoise. Consulté le 28.01.2024. https://www.liip.ch/fr/blog/demande-a-lausannegpt-tout-ce-qui-concerne-l-administration-lausannoise.
Sun Yutao, Dong Li, Huang Shaohan et al.. 2023. Retentive Network: A Successor to Transformer for Large Language Models. arXiv, pp. 1-14.
Sutskever Ilya, Vinyals Oriol et Le Quoc. V. 2014. Sequence to sequence learning with neural networks. Advances in neural information processing systems 27, pp. 1-9.
Tangi Luca, van Noordt Colin, Combetto Marco et al.. 2022. AI Watch - European landscape on the use of artificial intelligence by the public sector. Publications Office of the European Union, 74 pages.
Touvron Hugo, Martin Louis et Stone Kevin. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv, pp. 1-77.
Vaswani Ashish, Shazeer Noam, Parmar Niki et al.. 2017. Attention Is All You Need. 31st Conference on Neural Information Processing Systems, pp. 1-11.
Velinov Alex. SPARK Framework: Integrating AI in Your Business. Consulté le 06.01.2024. https://www.linkedin.com/pulse/spark-framework-integrating-ai-your-business-alex-velinov.
Wan Zhongwei, Wang Xin, Liu Che et al.. 2023. Efficient Large Language Models: A Survey. arXiv, pp. 1-59.
Wang Lei, Chen Wei, Yang Wenjia et al.. 2020. A State-of-the-Art Review on Image Synthesis with Generative Adversarial Networks. IEEE Access 8, pp. 63514-63537.
Weerts Sophie. 2023a. Droit. Dans : Comprendre et concevoir l’administration publique – Le modèle IDHEAP (de Soguel Nils, Bundi Pirmin, Mettler Tobias et al.). Presses polytechniques et universitaires romandes, 343 pages.
Weerts Sophie. 2023b. Ethique. Dans : Comprendre et concevoir l’administration publique – Le modèle IDHEAP (de Soguel Nils, Bundi Pirmin, Mettler Tobias et al.). Presses polytechniques et universitaires romandes, 343 pages.
Weerts Sophie. 2023c. Valeurs. Dans : Comprendre et concevoir l’administration publique – Le modèle IDHEAP (de Soguel Nils, Bundi Pirmin, Mettler Tobias et al.). Presses polytechniques et universitaires romandes, 343 pages.
Wei Jason, Wang Xuezhi, Schuurmans Dale et al.. 2022. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. Advances in Neural Information Processing Systems 35, pp. 1-43.
Wirtz Bernd W, Weyerer Jan C. et Geyer Carolin. 2019. Artificial Intelligence and the Public Sector - Applications and Challenges. International Journal of Public Administration 42(7), pp. 596-615.
Wu Yonghui, Schuster Mike, Chen Zhifeng, et al.. 2016. Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. arXiv, pp. 1-23.
Yair Zalmanovitch. 2014. Ne réinventons pas la roue : la recherche d'une identité pour l'administration publique. Revue Internationale des Sciences Administratives 80(4), pp. 857-875.
Yang Diyi. 2024a. Lecture 11: Efficient Adaptation (slides) – Natural Language Processing with Deep Learning CS224N. Stanford University. https://web.stanford.edu/class/cs224n/slides/cs224n-2024-lecture11-adaptation.pdf.
Yang Diyi 2024b. Lecture 12: Question Answering (slides) – Natural Language Processing with Deep Learning CS224N. Stanford University. https://web.stanford.edu/class/cs224n/slides/cs224n-2024-lecture12-QA.pdf.
Yang Diyi et Hashimoto Tatsunori. 2024. Lecture 1: Introduction and Word Vector (slides) – Natural Language Processing with Deep Learning CS224N. Stanford University. https://web.stanford.edu/class/cs224n/slides/cs224n-2024-lecture01-wordvecs1-public.pdf.
Yin Wenpeng, Kann Katharina, Yu Mo et al.. 2017. Comparative Study of CNN and RNN for Natural Language Processing. arXiv, pp. 1-7.
Young Tom, Hazarika Devamanyu, Poria Soujanya et al.. 2018. Recent trends in deep learning based natural language processing. IEEE Computational Intelligence Magazine 13(3), pp. 55-75.
Yvon François. 2022. Le modèle Transformer: un "couteau suisse" pour le traitement automatique des langues. Techniques de l'Ingénieur.
Zhang Yizhe, Sun Siqi, Galley Michel et al.. 2020. DIALOGPT: Large-scale generative pre-training for conversational response generation. Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 270-278.
Zhang Shuang, Fan Rui, Liu Yuti et al.. 2023. Applications of transformer-based language models in bioinformatics: A survey. Bioinformatics Advances 3(1), pp. 1-19.
Zhao Wayne Xin, Zhou Kun, Li Junyi et al.. 2023. A Survey of Large Language Models. arXiv, pp. 1-124.




{% include links.html %}
